# 5ì£¼ì°¨ - ë©€í‹°ëª¨ë‹¬ AI ììœ¨ì£¼í–‰ ì‹¤í—˜

## ğŸ“š ê°œìš”

5ì£¼ì°¨ì—ì„œëŠ” **ë©€í‹°ëª¨ë‹¬ AIì˜ í•µì‹¬ ê°œë…**ì„ í•™ìŠµí•˜ê³  ì´ë¥¼ **ììœ¨ì£¼í–‰ ì‹œìŠ¤í…œì— ì ìš©í•˜ëŠ” ì‹¤í—˜**ì„ ì§„í–‰í•©ë‹ˆë‹¤. CLIP, BLIP-2, BEV ë“±ì˜ ìµœì‹  ë©€í‹°ëª¨ë‹¬ ê¸°ìˆ ì„ ì´í•´í•˜ê³ , ì‹¤ì œ ì½”ë“œë¥¼ í†µí•´ ììœ¨ì£¼í–‰ í™˜ê²½ì—ì„œì˜ í™œìš© ê°€ëŠ¥ì„±ì„ ê²€ì¦í•©ë‹ˆë‹¤.

## ğŸ¯ í•™ìŠµ ëª©í‘œ

1. **ë©€í‹°ëª¨ë‹¬ í•µì‹¬ ê°œë…** ì´í•´ (CLIP/BLIP-2/BEV)
2. **ììœ¨ì£¼í–‰ ë°ì´í„°ì…‹** êµ¬ì„± ê° ì¡ê¸° (nuScenes/Waymo)
3. **CLIP ê¸°ë°˜ zero-shot/ê²€ìƒ‰Â·ë¦¬íŠ¸ë¦¬ë²Œ** ë¯¸ë‹ˆì‹¤í—˜ ìˆ˜í–‰
4. **"ììœ¨ì£¼í–‰ì— ë©€í‹°ëª¨ë‹¬ì„ ì–´ë–»ê²Œ ê½‚ì„ì§€"** ì ìš© ì•„ì´ë””ì–´ ë©”ëª¨

## ğŸ“ íŒŒì¼ êµ¬ì¡°

```
4ì£¼ì°¨/
â”œâ”€â”€ README.md                           # í˜„ì¬ íŒŒì¼
â”œâ”€â”€ requirements.txt                    # í•„ìˆ˜ íŒ¨í‚¤ì§€ ëª©ë¡
â”œâ”€â”€ clip_experiment.py                  # CLIP ì‹¤í—˜ ì½”ë“œ
â”œâ”€â”€ blip2_demo.py                       # BLIP-2 ë°ëª¨ ì½”ë“œ
â””â”€â”€ autonomous_driving_multimodal.py    # í†µí•© ë©€í‹°ëª¨ë‹¬ ì‹œìŠ¤í…œ
```

## ğŸš€ ì‹¤í–‰ ë°©ë²•

### 1. í™˜ê²½ ì„¤ì •

```bash
# ê°€ìƒí™˜ê²½ ìƒì„± (ê¶Œì¥)
python -m venv multimodal_env
source multimodal_env/bin/activate  # Linux/Mac
# ë˜ëŠ”
multimodal_env\Scripts\activate     # Windows

# íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt
```

### 2. CLIP ì‹¤í—˜ ì‹¤í–‰

```bash
python clip_experiment.py
```

**ì£¼ìš” ê¸°ëŠ¥:**
- Zero-shot ë¶„ë¥˜ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
- ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì‹¤í—˜
- í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ íš¨ê³¼ ê²€ì¦

### 3. BLIP-2 ë°ëª¨ ì‹¤í–‰

```bash
python blip2_demo.py
```

**ì£¼ìš” ê¸°ëŠ¥:**
- ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„±
- ì§ˆë¬¸-ë‹µë³€ ì‹œìŠ¤í…œ
- ìƒí™© ë³´ê³ ì„œ ìƒì„±
- êµì°¨ ê²€ì¦ í…ŒìŠ¤íŠ¸

### 4. í†µí•© ë©€í‹°ëª¨ë‹¬ ì‹œìŠ¤í…œ ì‹¤í–‰

```bash
python autonomous_driving_multimodal.py
```

**ì£¼ìš” ê¸°ëŠ¥:**
- CLIP ê¸°ë°˜ ìœ„í—˜ ìš”ì†Œ ê°ì§€
- BLIP-2 ìƒí™© ë³´ê³ ì„œ ìƒì„±
- BEV + ì–¸ì–´ ì§ˆì˜ ì‹œìŠ¤í…œ
- ì•ˆì „ ì¡°ì¹˜ íŠ¸ë¦¬ê±°

## ğŸ”¬ ì‹¤í—˜ ë‚´ìš©

### 1. CLIP ì‹¤í—˜ (clip_experiment.py)

#### Zero-shot ë¶„ë¥˜
- **ë°ì´í„°ì…‹**: ììœ¨ì£¼í–‰ ê´€ë ¨ ì´ë¯¸ì§€ 50ì¥
- **í´ë˜ìŠ¤**: traffic light, pedestrian, car, traffic sign, construction
- **í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿**:
  - `"a photo of a {class}."`
  - `"traffic scene with a {class}."`
  - í•œêµ­ì–´ í”„ë¡¬í”„íŠ¸

#### ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ê²€ìƒ‰
- **ì¿¼ë¦¬**: "red traffic light", "pedestrian crossing", "construction cone"
- **í‰ê°€ ë©”íŠ¸ë¦­**: Recall@1, Recall@5, í‰ê·  ë­í¬

### 2. BLIP-2 ì‹¤í—˜ (blip2_demo.py)

#### ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„±
- ììœ¨ì£¼í–‰ ìƒí™©ì— ëŒ€í•œ ìì—°ì–´ ì„¤ëª… ìƒì„±
- êµí†µ ìƒí™© ë¶„ì„ ë° ìš”ì•½

#### ì§ˆë¬¸-ë‹µë³€ ì‹œìŠ¤í…œ
- 23ê°œ ììœ¨ì£¼í–‰ ê´€ë ¨ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„±
- ìƒí™©ë³„ ì¼ê´€ì„± ê²€ì¦

### 3. í†µí•© ì‹œìŠ¤í…œ (autonomous_driving_multimodal.py)

#### ìœ„í—˜ ìš”ì†Œ ê°ì§€
- **ì¹´í…Œê³ ë¦¬**: construction, pedestrian, emergency, accident, weather
- **ì„ê³„ê°’ ê¸°ë°˜** ìœ„í—˜ë„ í‰ê°€ (LOW/MEDIUM/HIGH)

#### ìƒí™© ë³´ê³ ì„œ ìƒì„±
- ìì—°ì–´ ê¸°ë°˜ ìƒí™© ìš”ì•½
- ë¡œê·¸ ì‹œìŠ¤í…œì„ í†µí•œ ê¸°ë¡ ê´€ë¦¬

#### BEV + ì–¸ì–´ ì§ˆì˜
- ê³µê°„ì  ì •ë³´ì™€ ìì—°ì–´ ì§ˆì˜ ê²°í•©
- "ì™¼ì°¨ì„  ë§‰í˜?", "ë³´í–‰ì ìœ„ì¹˜?" ë“± ì§ˆì˜ ì²˜ë¦¬

## ğŸ“Š ì˜ˆìƒ ê²°ê³¼

### CLIP ì‹¤í—˜ ê²°ê³¼
| í”„ë¡¬í”„íŠ¸ ìœ í˜• | ì •í™•ë„ | ì£¼ìš” íŠ¹ì§• |
|---------------|--------|-----------|
| ê¸°ë³¸ ì˜ì–´ | 72% | ì¼ë°˜ì ì¸ ê°ì²´ ì¸ì‹ ìš°ìˆ˜ |
| ë§¥ë½ í¬í•¨ | 78% | ì‘ì€ ê°ì²´(í‘œì§€íŒ) ì¸ì‹ë¥  í–¥ìƒ |
| í•œêµ­ì–´ | 65% | ì–¸ì–´ ê°„ ì„±ëŠ¥ ì°¨ì´ ì¡´ì¬ |

### ê²€ìƒ‰ ì„±ëŠ¥
| ì¿¼ë¦¬ | Recall@1 | Recall@5 | í‰ê·  ë­í¬ |
|------|----------|----------|-----------|
| red traffic light | 85% | 92% | 1.8 |
| pedestrian crossing | 72% | 88% | 2.3 |
| construction cone | 68% | 85% | 2.7 |

## ğŸš— ììœ¨ì£¼í–‰ ì ìš© ì•„ì´ë””ì–´

### 1. CLIP ê¸°ë°˜ ìœ„í—˜êµ¬ì—­ íŠ¸ë¦¬ê±°
```python
# ìœ„í—˜ ìš”ì†Œ í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ
danger_prompts = [
    "construction cone on road",
    "pedestrian crossing street",
    "emergency vehicle with lights",
    "traffic accident scene"
]

# ì„ê³„ê°’ ì´ˆê³¼ ì‹œ ê°ì† ëª…ë ¹
if max(clip_scores) > threshold:
    trigger_slowdown()
```

### 2. BLIP-2 ìƒí™© ë³´ê³ ì„œ
```
ì…ë ¥ ì´ë¯¸ì§€ â†’ "ì¢Œì¸¡ ì°¨ë¡œì— ì •ì§€ì°¨ëŸ‰, ë³´í–‰ìê°€ ì ‘ê·¼ ì¤‘"
â†’ ì˜ì‚¬ê²°ì • ë¡œê·¸ì— ê¸°ë¡
â†’ ì‚¬ê³  ë¶„ì„ ì‹œ ì°¸ê³  ìë£Œ
```

### 3. BEV + ì–¸ì–´ ì§ˆì˜
```python
# ì§ˆì˜ ì˜ˆì‹œ
queries = [
    "Is the left lane blocked?",
    "Where are the pedestrians?",
    "Is there space to merge?"
]

# BEV + ì–¸ì–´ ëª¨ë¸ë¡œ ì‘ë‹µ ìƒì„±
response = bev_language_model(bev_representation, query)
```

## âš ï¸ ì£¼ì˜ì‚¬í•­

### í•˜ë“œì›¨ì–´ ìš”êµ¬ì‚¬í•­
- **GPU**: CUDA ì§€ì› GPU ê¶Œì¥ (ìµœì†Œ 4GB VRAM)
- **RAM**: ìµœì†Œ 8GB (16GB ê¶Œì¥)
- **ì €ì¥ê³µê°„**: ìµœì†Œ 5GB (ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í¬í•¨)

### ì œì•½ì‚¬í•­
- **ì‹¤í—˜ìš© ì½”ë“œ**: ì‹¤ì œ ììœ¨ì£¼í–‰ì—ëŠ” ì¶”ê°€ ê²€ì¦ í•„ìš”
- **ë”ë¯¸ ë°ì´í„°**: ì¼ë¶€ ê¸°ëŠ¥ì€ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ì‚¬ìš©
- **ì„±ëŠ¥**: ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ìµœì í™” í•„ìš”

## ğŸ” ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ì˜¤ë¥˜

1. **CUDA ë©”ëª¨ë¦¬ ë¶€ì¡±**
   ```bash
   # CPU ëª¨ë“œë¡œ ì‹¤í–‰
   export CUDA_VISIBLE_DEVICES=""
   ```

2. **ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨**
   ```bash
   # ìˆ˜ë™ìœ¼ë¡œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
   python -c "import clip; clip.load('ViT-B/32')"
   ```

3. **íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì˜¤ë¥˜**
   ```bash
   # pip ì—…ê·¸ë ˆì´ë“œ
   pip install --upgrade pip
   pip install -r requirements.txt --force-reinstall
   ```


## ğŸ“– ì°¸ê³  ìë£Œ

### ë…¼ë¬¸
- [CLIP: Learning Transferable Visual Models From Natural Language Supervision](https://arxiv.org/abs/2103.00020)
- [BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models](https://arxiv.org/abs/2301.12597)
- [BEVFormer: Learning Bird's-Eye-View Representation from Multi-Camera Images via Spatiotemporal Transformers](https://arxiv.org/abs/2203.17270)

### ë°ì´í„°ì…‹
- [nuScenes](https://www.nuscenes.org/)
- [Waymo Open Dataset](https://waymo.com/open/)

### ë„êµ¬
- [OpenAI CLIP](https://github.com/openai/CLIP)
- [LAVIS (BLIP-2)](https://github.com/salesforce/LAVIS)
- [BEVFormer](https://github.com/fundamentalvision/BEVFormer)

